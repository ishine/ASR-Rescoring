task: "scoring"

method: "MD_MWED"

seed: 10

device: "cuda:0"

dev_feature:
  - hyps_token_ids
dev_feature_path: 
  - "../espnet_data/alfred/dev/hyps_text.json"
dev_output_format: "../espnet_data/alfred/dev/hyps_score.json"

test_feature:
  - hyps_token_ids
test_feature_path: 
  - "../espnet_data/alfred/test/hyps_text.json"
test_output_format: "../espnet_data/alfred/test/hyps_score.json"

checkpoint_path: "result/retrain_MD_MWED/checkpoint_5.pth"
output_path: "result/retrain_MD_MWED"

# the unit of batch size is utterence
# if batch_size = m, means m*n-best hypotheses in one batch
batch_size: 15

# if you don't want to process too much data (like for debugging)
# you can set this value to a small number.
max_utt: 999999999
n_best: 10

dataloader:
  num_worker: 5

model:
  bert: "bert-base-chinese"